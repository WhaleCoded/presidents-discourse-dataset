{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from IPython.utils import io\n",
    "import time\n",
    "\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import CongressDataset\n",
    "from token_map import TokenMap, create_re_from_formatted_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn;\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 300\n",
    "DICTIONARY_SIMILARITY_THRESHOLD = 0.5\n",
    "WORD_MIN_COUNT = 100\n",
    "NUM_RECURRENCES = 3\n",
    "\n",
    "DICTIONARY_SAVE_PATH = os.path.join(os.path.curdir, \"data\", \"ensamble_fine_tuning\", \"json_dicts\")\n",
    "os.makedirs(DICTIONARY_SAVE_PATH, exist_ok=True)\n",
    "MODELS_SAVE_PATH = os.path.join(os.path.curdir, \"data\", \"ensamble_cluster_smart_dicts\", \"embedding_models\")\n",
    "os.makedirs(MODELS_SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary Fine Tuning\n",
    "LARGE_CLUSTER_WEIGHT = 0.02\n",
    "NUM_ENSAMBLE_RERUNS = 20\n",
    "NUM_CLUSTERS_TO_CHECK = range(2, 13)\n",
    "NUM_CLUSTER_RERUNS = 20\n",
    "\n",
    "PREVIOUS_TERM_BOOST = 3\n",
    "NUM_RECURRENCE_BOOST = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading token map from disk...\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = os.path.join(\n",
    "        os.path.curdir, \"data\", \"cr_speech_sentences_with_speaker_and_date.csv\"\n",
    "    )\n",
    "FORMATTED_DICT_PATH = os.path.join(\n",
    "    os.path.curdir,\n",
    "    \"data\",\n",
    "    \"revised_normalized_smart_dicts\", \n",
    "    \"json_dicts\", \n",
    "    \"2001-2020_recursive_dict.json\"\n",
    ")\n",
    "token_map_load_path = os.path.join(os.path.curdir, \"data\", \"revised_normalized_smart_dicts\", \"token_map\")\n",
    "\n",
    "dictionary_re = create_re_from_formatted_dictionary(FORMATTED_DICT_PATH)\n",
    "\n",
    "token_map = TokenMap(DATA_PATH, token_map_load_path, dictionary_re=dictionary_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[(2001, 2020), (1993, 2000), (1973, 1992), (1953, 1972), (1933, 1952), (1913, 1932), (1893, 1912), (1873, 1892)]\n"
     ]
    }
   ],
   "source": [
    "dictionary_time_periods = []\n",
    "\n",
    "start_year = 1873\n",
    "end_year = 2000\n",
    "\n",
    "\n",
    "temp_year = 1873\n",
    "while temp_year < end_year - 1:\n",
    "    dictionary_time_periods.append((temp_year, temp_year + 19))\n",
    "    temp_year += 20\n",
    "dictionary_time_periods = sorted(dictionary_time_periods, reverse=True)\n",
    "\n",
    "dictionary_time_periods[0] = (1993, 2000)\n",
    "dictionary_time_periods = [(2001, 2020)] + dictionary_time_periods\n",
    "\n",
    "print(len(dictionary_time_periods))\n",
    "print(dictionary_time_periods[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the starting dictionaries\n",
    "with open(FORMATTED_DICT_PATH, \"r\") as f:\n",
    "    curr_dicts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data_for_gensim(data_item):\n",
    "    return data_item[\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_sim_score(word, dictionary_terms, model):\n",
    "    tot_sim_score = 0\n",
    "    num_valid_terms = 0\n",
    "\n",
    "    for term in dictionary_terms:\n",
    "        if term != word:\n",
    "            try:\n",
    "                specific_score = model.wv.similarity(word, term)\n",
    "                tot_sim_score += specific_score\n",
    "                num_valid_terms += 1\n",
    "            except KeyError as e:\n",
    "                pass\n",
    "\n",
    "    return tot_sim_score / num_valid_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median_sim_score(word, dictionary_terms, model):\n",
    "    all_sim_scores = []\n",
    "\n",
    "    for term in dictionary_terms:\n",
    "        if term != word:\n",
    "            try:\n",
    "                specific_score = model.wv.similarity(word, term)\n",
    "                all_sim_scores.append(specific_score)\n",
    "            except KeyError as e:\n",
    "                passos.path.join(\"data\", \"ensamble_fine_tuning\", \"original_dict.json\")\n",
    "\n",
    "    all_sim_scores = sorted(all_sim_scores)\n",
    "    median_score = all_sim_scores[len(all_sim_scores) // 2]\n",
    "    if word in dictionary_terms:\n",
    "        # Boost the score of words that are already in the dictionary\n",
    "        # print(f\"Boosting {token_map.get_token_from_id(word)} from {median_score} to {median_score * (1 + PREVIOUS_TERM_BOOST)} because it is already in the dictionary\")\n",
    "        median_score = median_score * (1 + PREVIOUS_TERM_BOOST)\n",
    "\n",
    "    return median_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dictionary(model, dictionary_terms, previous_dictionary_size: int):\n",
    "     new_term_counts = {}\n",
    "     new_term_scores = {}\n",
    "\n",
    "     for term in dictionary_terms:\n",
    "          try:\n",
    "               top_matching_words = model.wv.most_similar(term, topn=previous_dictionary_size)\n",
    "\n",
    "               for (word, sim_score) in top_matching_words:\n",
    "                    # Keep track of max sim score for each word 0\n",
    "\n",
    "                    \n",
    "                    if not (word in new_term_scores):\n",
    "                         # Only needs to be calculated once\n",
    "                         # average_sim_score = calculate_average_sim_score(word, dictionary_terms, model)\n",
    "                         median_score = calculate_median_sim_score(word, dictionary_terms, model)\n",
    "                         new_term_scores[word] = median_score\n",
    "                    else:\n",
    "                         # Boost the score of words that appear more times\n",
    "                         # new_term_scores[word] = new_term_scores[word] * (1 + NUM_RECURRENCE_BOOST)\n",
    "                         original_score = new_term_scores[word]\n",
    "                         # median_score = calculate_median_sim_score(word, dictionary_terms, model)\n",
    "                         new_term_scores[word] = original_score * (1 + NUM_RECURRENCE_BOOST)\n",
    "                         \n",
    "\n",
    "                    # Keep track of how many times a word appears in the top matching words\n",
    "                    # if sim_score > DICTIONARY_SIMILARITY_THRESHOLD:\n",
    "                    #      if word not in new_term_counts:\n",
    "                    #           new_term_counts[word] = 0\n",
    "                    #      new_term_counts[word] += 1\n",
    "                         \n",
    "          except KeyError as e:\n",
    "               translated_term = token_map.get_token_from_id(term)\n",
    "               # print(f\"{translated_term}-{term}: {e}\")\n",
    "\n",
    "     # print(\"Previous dictionary reoccurrences:\")\n",
    "     # print({k: v for k, v in sorted(previous_dict_reocurrences.items(), key=lambda item: item[0])})\n",
    "     # Sort dictionaries and remove words that don't appear enough times\n",
    "     # new_term_counts = {k: v for k, v in sorted(new_term_counts.items(), key=lambda item: item[1], reverse=True) if v >= NUM_RECURRENCES}     \n",
    "     new_term_scores = {k: v for k, v in sorted(new_term_scores.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "\n",
    "     # Compile the dictionary from the recurring words\n",
    "     final_dictionary_terms = set()\n",
    "     final_dictionary_scores = {}\n",
    "     # for term in new_term_counts.keys():\n",
    "     #      if len(final_dictionary_terms) >= previous_dictionary_size:\n",
    "     #           break\n",
    "     #      final_dictionary_terms.add(term)\n",
    "\n",
    "     # Add words based on similarity score until the dictionary is full\n",
    "     for term, score in new_term_scores.items():\n",
    "          if len(final_dictionary_terms) >= previous_dictionary_size:\n",
    "               break\n",
    "          final_dictionary_terms.add(term)\n",
    "          final_dictionary_scores[term] = score\n",
    "     \n",
    "     # Remove the unknown token if it is in the dictionary\n",
    "     # The unkown token is meaningless\n",
    "     if token_map.unkown_id in final_dictionary_terms:\n",
    "          final_dictionary_terms.remove(token_map.unkown_id)\n",
    "          final_dictionary_scores.pop(token_map.unkown_id)\n",
    "\n",
    "     # print(f\"Previous dictionary reocurrences: {sorted([token_map.get_token_from_id(term) for term in final_dictionary_terms if term in dictionary_terms]) }\")\n",
    "     # print(f\"Average dictionary_sim_score for with previous boost: {sum(final_dictionary_scores.values()) / len(final_dictionary_scores)}\")\n",
    "     # print(f\"Average score of top 25 terms: {sum(sorted(final_dictionary_scores.values(), reverse=True)[:25]) / 25}. There are {len(final_dictionary_scores)} terms in the dictionary.\")\n",
    "\n",
    "     return list(final_dictionary_terms), final_dictionary_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, MeanShift\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def calculate_cluster_centroids(embeddings):\n",
    "    # Find optimal number of clusters\n",
    "    optimal_num_clusters = 0\n",
    "    best_silhouette_score = 0\n",
    "    best_cluster_labels = None\n",
    "\n",
    "    for _ in range(NUM_CLUSTER_RERUNS):\n",
    "        for num_clusters in NUM_CLUSTERS_TO_CHECK:\n",
    "            kmeans = KMeans(n_clusters=num_clusters, init=\"k-means++\", max_iter=2000, tol=1e-5).fit(embeddings)\n",
    "            # with io.capture_output() as captured:\n",
    "            #     kmeans = SpectralClustering(affinity=\"rbf\", assign_labels=\"kmeans\", n_clusters=num_clusters, n_init=NUM_CLUSTER_RERUNS).fit(embeddings)\n",
    "            # kmeans = AgglomerativeClustering(n_clusters=num_clusters, linkage=\"complete\").fit(embeddings)\n",
    "            cluster_labels = kmeans.labels_\n",
    "            num_unique_labels = len(set(cluster_labels))\n",
    "            \n",
    "            if num_unique_labels > 1:\n",
    "                num_clusters = num_unique_labels\n",
    "                silhouette_avg = silhouette_score(embeddings, cluster_labels)       \n",
    "\n",
    "                if silhouette_avg > best_silhouette_score:\n",
    "                    # print(f\"Number of clusters: {num_clusters} with silhouette score: {silhouette_avg}\") \n",
    "                    # We want to discourge large amounts of clusters, so negatibely weight larger clusters\n",
    "                    if silhouette_avg - ((max(num_clusters - optimal_num_clusters, 0)) * (best_silhouette_score*LARGE_CLUSTER_WEIGHT)) > best_silhouette_score:\n",
    "                        best_silhouette_score = silhouette_avg\n",
    "                        optimal_num_clusters = num_clusters\n",
    "                        best_cluster_labels = cluster_labels\n",
    "                        # print(f\"New optimal number of clusters: {optimal_num_clusters} with silhouette score: {best_silhouette_score}\")\n",
    "\n",
    "\n",
    "    # print(f\"Optimal number of clusters: {optimal_num_clusters} with silhouette score: {best_silhouette_score}\")\n",
    "    return len(set(best_cluster_labels)), best_cluster_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cluster_distributions(cluster_labels, num_clusters):\n",
    "    cluster_distributions = {}\n",
    "    for i in range(num_clusters):\n",
    "        cluster_distributions[i] = 0\n",
    "\n",
    "    for label in cluster_labels:\n",
    "        cluster_distributions[label] += 1\n",
    "\n",
    "    return cluster_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_of_scores_to_final_scores(list_scores_dict):\n",
    "    \"\"\"\n",
    "    Returns a list of terms translated to english sorted by their values in descending order\n",
    "    \"\"\"\n",
    "    final_scores = {}\n",
    "\n",
    "    total_num_recurrences = 0\n",
    "    for term, score_lists in list_scores_dict.items():\n",
    "        num_recurrences = len(score_lists)\n",
    "        if num_recurrences > 1:\n",
    "            total_num_recurrences += 1\n",
    "\n",
    "        # Each term with multiple occurences gets a percentage boost over the average score\n",
    "        # TODO: Consider using the median here instead of the average\n",
    "        # if num_recurrences > 1:\n",
    "        #     print(f\"Term {token_map.get_token_from_id(term)} has {num_recurrences} recurrences\")\n",
    "    \n",
    "        final_scores[term] = (sum(score_lists) / num_recurrences) * (1 + (num_recurrences * NUM_RECURRENCE_BOOST))\n",
    "        \n",
    "    final_dictionary = [token_map.get_token_from_id(k) for k, v in sorted(final_scores.items(), key=lambda item: item[1], reverse=True)]\n",
    "    final_scores = [v for k, v in sorted(final_scores.items(), key=lambda item: item[1], reverse=True)]\n",
    "    return final_dictionary, final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_ensamble_dicts(ensamble_dicts, desired_dict_sizes):\n",
    "    combined_dict = {}\n",
    "\n",
    "    for moral_foundation, dict_terms in ensamble_dicts.items():\n",
    "        # Convert list of scores to final scores\n",
    "        sorted_terms, sorted_scores = convert_list_of_scores_to_final_scores(dict_terms)\n",
    "        final_dict_terms = sorted_terms[:desired_dict_sizes[moral_foundation]]\n",
    "        final_dict_scores = sorted_scores[:desired_dict_sizes[moral_foundation]]\n",
    "\n",
    "        print(f\"Final dictionary size for {moral_foundation}: {len(final_dict_terms)}\")\n",
    "        print(f\"Average score for {moral_foundation}: {sum(final_dict_scores) / len(final_dict_scores)}\")\n",
    "\n",
    "        combined_dict[moral_foundation] = final_dict_terms\n",
    "\n",
    "    return combined_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current time period is (2001, 2020).  1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating dictionary: 100%|██████████| 20/20 [11:01<00:00, 33.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dictionary size for Harm: 97\n",
      "Average score for Harm: 0.6725509970279776\n",
      "Final dictionary size for Authority: 159\n",
      "Average score for Authority: 0.35238193153155456\n",
      "Final dictionary size for Fairness: 85\n",
      "Average score for Fairness: 0.6687338615622314\n",
      "Final dictionary size for Institutional_Purity: 282\n",
      "Average score for Institutional_Purity: 2.1073226558391864\n",
      "Final dictionary size for Ingroup: 122\n",
      "Average score for Ingroup: 0.3510243878094075\n",
      "Final dictionary size for Sexual_Purity: 39\n",
      "Average score for Sexual_Purity: 0.6107474650747837\n",
      "The current time period is (1993, 2000).  2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating dictionary: 100%|██████████| 20/20 [08:35<00:00, 25.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dictionary size for Harm: 97\n",
      "Average score for Harm: 1.366562112361466\n",
      "Final dictionary size for Authority: 159\n",
      "Average score for Authority: 1.1703353846955982\n",
      "Final dictionary size for Fairness: 85\n",
      "Average score for Fairness: 1.665326845509773\n",
      "Final dictionary size for Institutional_Purity: 282\n",
      "Average score for Institutional_Purity: 71.39386449251744\n",
      "Final dictionary size for Ingroup: 122\n",
      "Average score for Ingroup: 1.4486743085253013\n",
      "Final dictionary size for Sexual_Purity: 39\n",
      "Average score for Sexual_Purity: 2.154338559027901\n",
      "The current time period is (1973, 1992).  3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating dictionary: 100%|██████████| 20/20 [07:13<00:00, 21.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dictionary size for Harm: 97\n",
      "Average score for Harm: 2.053922802604986\n",
      "Final dictionary size for Authority: 159\n",
      "Average score for Authority: 1.9696715458679355\n",
      "Final dictionary size for Fairness: 85\n",
      "Average score for Fairness: 3.197324473690881\n",
      "Final dictionary size for Institutional_Purity: 282\n",
      "Average score for Institutional_Purity: 144.74328300572517\n",
      "Final dictionary size for Ingroup: 122\n",
      "Average score for Ingroup: 2.1552388369481674\n",
      "Final dictionary size for Sexual_Purity: 39\n",
      "Average score for Sexual_Purity: 2.299594514488236\n",
      "The current time period is (1953, 1972).  4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating dictionary: 100%|██████████| 20/20 [07:22<00:00, 22.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dictionary size for Harm: 97\n",
      "Average score for Harm: 2.1374943050079804\n",
      "Final dictionary size for Authority: 159\n",
      "Average score for Authority: 2.624858065160791\n",
      "Final dictionary size for Fairness: 85\n",
      "Average score for Fairness: 4.437114519310292\n",
      "Final dictionary size for Institutional_Purity: 282\n",
      "Average score for Institutional_Purity: 167.31718290592593\n",
      "Final dictionary size for Ingroup: 122\n",
      "Average score for Ingroup: 2.692563492733906\n",
      "Final dictionary size for Sexual_Purity: 39\n",
      "Average score for Sexual_Purity: 1.8640751595818938\n",
      "The current time period is (1933, 1952).  5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating dictionary: 100%|██████████| 20/20 [05:48<00:00, 17.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dictionary size for Harm: 97\n",
      "Average score for Harm: 2.5075894381692874\n",
      "Final dictionary size for Authority: 159\n",
      "Average score for Authority: 3.3274933114910756\n",
      "Final dictionary size for Fairness: 85\n",
      "Average score for Fairness: 4.7022972457260765\n",
      "Final dictionary size for Institutional_Purity: 282\n",
      "Average score for Institutional_Purity: 87.44002494684513\n",
      "Final dictionary size for Ingroup: 122\n",
      "Average score for Ingroup: 2.7069900304288392\n",
      "Final dictionary size for Sexual_Purity: 39\n",
      "Average score for Sexual_Purity: 2.0919637468833407\n",
      "The current time period is (1913, 1932).  6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating dictionary: 100%|██████████| 20/20 [07:00<00:00, 21.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dictionary size for Harm: 97\n",
      "Average score for Harm: 3.026545867613879\n",
      "Final dictionary size for Authority: 159\n",
      "Average score for Authority: 7.273428048182514\n",
      "Final dictionary size for Fairness: 85\n",
      "Average score for Fairness: 5.4240848391917975\n",
      "Final dictionary size for Institutional_Purity: 282\n",
      "Average score for Institutional_Purity: 150.26627637156614\n",
      "Final dictionary size for Ingroup: 122\n",
      "Average score for Ingroup: 5.5310901010173374\n",
      "Final dictionary size for Sexual_Purity: 39\n",
      "Average score for Sexual_Purity: 3.652501325398393\n",
      "The current time period is (1893, 1912).  7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating dictionary: 100%|██████████| 20/20 [05:10<00:00, 15.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dictionary size for Harm: 97\n",
      "Average score for Harm: 3.313316391971528\n",
      "Final dictionary size for Authority: 159\n",
      "Average score for Authority: 10.681123851893455\n",
      "Final dictionary size for Fairness: 85\n",
      "Average score for Fairness: 5.330837913587267\n",
      "Final dictionary size for Institutional_Purity: 282\n",
      "Average score for Institutional_Purity: 142.37346695918276\n",
      "Final dictionary size for Ingroup: 122\n",
      "Average score for Ingroup: 5.682691466273027\n",
      "Final dictionary size for Sexual_Purity: 39\n",
      "Average score for Sexual_Purity: 3.281960462689158\n",
      "The current time period is (1873, 1892).  8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating dictionary: 100%|██████████| 20/20 [05:35<00:00, 16.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dictionary size for Harm: 97\n",
      "Average score for Harm: 3.301530697500771\n",
      "Final dictionary size for Authority: 159\n",
      "Average score for Authority: 16.28558236446472\n",
      "Final dictionary size for Fairness: 85\n",
      "Average score for Fairness: 5.598496632137639\n",
      "Final dictionary size for Institutional_Purity: 282\n",
      "Average score for Institutional_Purity: 185.2805822868984\n",
      "Final dictionary size for Ingroup: 122\n",
      "Average score for Ingroup: 7.531977255233678\n",
      "Final dictionary size for Sexual_Purity: 39\n",
      "Average score for Sexual_Purity: 4.140269754010492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, time_period in enumerate(dictionary_time_periods):\n",
    "    term_counts_and_scores_by_dictionary = {}\n",
    "    desired_dict_sizes = {}\n",
    "    num_trained_models = 0\n",
    "    tot_train_time = 0\n",
    "    print(f\"The current time period is {time_period}.  {i+1}/{len(dictionary_time_periods)}\")\n",
    "    p_bar = tqdm(range(NUM_ENSAMBLE_RERUNS), desc=\"Calculating dictionary\")\n",
    "    for x in p_bar:\n",
    "        model_save_path = os.path.join(MODELS_SAVE_PATH, f\"{x}_{time_period[0]}_{time_period[1]}.model\")\n",
    "\n",
    "        if os.path.exists(model_save_path):\n",
    "            model = gensim.models.Word2Vec.load(model_save_path)\n",
    "        else:\n",
    "            # Load the data\n",
    "            dataset = CongressDataset(token_map=token_map, date_range=time_period)\n",
    "            dataset.map(format_data_for_gensim)\n",
    "\n",
    "            # Train and save the new model\n",
    "            model = gensim.models.Word2Vec(dataset, size=EMBEDDING_SIZE, min_count=WORD_MIN_COUNT, workers=12)\n",
    "            model.save(model_save_path)\n",
    "\n",
    "        for dict_name in curr_dicts.keys():\n",
    "            if dict_name not in term_counts_and_scores_by_dictionary:\n",
    "                term_counts_and_scores_by_dictionary[dict_name] = {}\n",
    "\n",
    "            # grab existing terms\n",
    "            dict_terms = curr_dicts[dict_name]\n",
    "            desired_dict_sizes[dict_name] = len(dict_terms)\n",
    "            translated_terms = [token_map.get_token_id_from_token(term) for term in dict_terms if token_map.get_token_id_from_token(term) in model.wv]\n",
    "\n",
    "            dictionary_embeddings = [embedding for embedding in model.wv[translated_terms]]\n",
    "\n",
    "            # Calculate the centroids of the clusters\n",
    "            # num_clusters, cluster_labels = calculate_cluster_centroids(dictionary_embeddings)\n",
    "            # cluster_distributions = calculate_cluster_distributions(cluster_labels, num_clusters)\n",
    "            # print(cluster_distributions)\n",
    "            # translated_terms_and_labels = list(zip(translated_terms, cluster_labels))\n",
    "\n",
    "            # Calculate the new dictionary terms\n",
    "            new_terms, new_term_scores = calculate_dictionary(model, translated_terms, len(dict_terms))\n",
    "\n",
    "            for term, score in new_term_scores.items():\n",
    "                if term not in term_counts_and_scores_by_dictionary[dict_name]:\n",
    "                    term_counts_and_scores_by_dictionary[dict_name][term] = []\n",
    "                term_counts_and_scores_by_dictionary[dict_name][term].append(score)\n",
    "\n",
    "    curr_dicts = combine_ensamble_dicts(term_counts_and_scores_by_dictionary, desired_dict_sizes)\n",
    "\n",
    "    # Save the new completed dictionary\n",
    "    new_dict_name = f\"{time_period[0]}-{time_period[1]}_recursive_dict.json\"\n",
    "    new_dict_path = os.path.join(DICTIONARY_SAVE_PATH, new_dict_name)\n",
    "    with open(new_dict_path, \"w+\") as f:\n",
    "        json.dump(curr_dicts, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "presidents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77b3f24db4760b8c61a784a6cf48a467feb1ad85c14ee10af44901428476a873"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
